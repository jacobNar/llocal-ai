import { app, BrowserWindow, ipcMain  } from 'electron';
import { ChatOllama, OllamaEmbeddings } from '@langchain/ollama';
import { MemoryVectorStore } from 'langchain/vectorstores/memory';
import { RecursiveCharacterTextSplitter } from 'langchain/text_splitter';
import { tool } from '@langchain/core/tools';
import { z } from 'zod';
import { createReactAgent } from '@langchain/langgraph/prebuilt';
import type { Document } from '@langchain/core/documents';
import { MemorySaver } from "@langchain/langgraph";
import { HumanMessage } from '@langchain/core/messages';

// This allows TypeScript to pick up the magic constants that's auto-generated by Forge's Webpack
declare const MAIN_WINDOW_WEBPACK_ENTRY: string;
declare const MAIN_WINDOW_PRELOAD_WEBPACK_ENTRY: string;

// Handle creating/removing shortcuts on Windows when installing/uninstalling.
if (require('electron-squirrel-startup')) {
  app.quit();
}
//APP GLOBALS
let mainWindow: BrowserWindow;
let vectorStore: MemoryVectorStore;
let agent: any;
const textSplitter = new RecursiveCharacterTextSplitter({ chunkSize: 200, chunkOverlap: 0 });

const createWindow = (): void => {
  // Create the browser window.
  mainWindow = new BrowserWindow({
    height: 600,
    width: 800,
    webPreferences: {
      preload: MAIN_WINDOW_PRELOAD_WEBPACK_ENTRY,
    },
  });

  // and load the index.html of the app.
  mainWindow.loadURL(MAIN_WINDOW_WEBPACK_ENTRY);

  // Open the DevTools.
  mainWindow.webContents.openDevTools();
};

app.on('ready', () => {
  initAgent();
  createWindow();
});

// Quit when all windows are closed, except on macOS. There, it's common for applications and their menu bar to stay active until the user quits explicitly with Cmd + Q.
app.on('window-all-closed', () => {
  if (process.platform !== 'darwin') {
    app.quit();
  }
});

app.on('activate', () => {
  initAgent();
  if (BrowserWindow.getAllWindows().length === 0) {
    createWindow();
  }
});


// Initialize LLM, embeddings, tools, and agent
const initAgent = () => {
  const llm = new ChatOllama({
    baseUrl: 'http://localhost:11434/',
    model: 'llama3.2',
    temperature: 0,
    maxRetries: 2,
  });

  const embeddings = new OllamaEmbeddings({
    baseUrl: 'http://localhost:11434/',
    model: 'llama3.2',
  });

  vectorStore = new MemoryVectorStore(embeddings);
  const memory = new MemorySaver();

  const similaritySearchTool = tool(async ({ query }: { query: string }): Promise<string> => {
    const results: Document[] = await vectorStore.similaritySearch(query, 30);
    return results.map(r => r.pageContent).join('\n\n');
  }, {
    name: 'Similarity Search Vectorized Websites',
    description: 'Search vector store for relevant content.',
    schema: z.object({
      query: z.string().describe('Search query'),
    }),
  });

  const tools = [similaritySearchTool];
  // const tools = []

  agent = createReactAgent({ llm, tools, checkpointer: memory});
  console.log("Agent initialized");
};

// IPC to handle user queries
ipcMain.handle('runQuery', async (event, message:string) => {
  const humanMessage = new HumanMessage(message)
  const result = await agent.invoke({ messages: [humanMessage] },{ configurable: { thread_id: "1" } });
  return result.messages;
});

